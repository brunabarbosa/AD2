---
title: "Lab3-parte2"
author: "Bruna"
date: "March 1, 2017"
output: html_document
---

### 1.Separe os dados em treino e teste;
```{r setup, cache=TRUE, message=FALSE, warning=FALSE}
library(ISLR)
library(readr)
library(caret)
library(dplyr)
library(reshape2)
library(caret)

set.seed(9560)
#setwd("~/AD2/Lab3-Parte2")
treino_classificacao_v2 <- read_csv("treino_classificacao_v2.csv")

##Reshape nos dados
classificacao.clean <- treino_classificacao_v2 %>%
  filter(!is.na(MAT_MEDIA_FINAL))

classificacao.clean$CREDITOS <- 4

##novo atributo
classificacao.clean[classificacao.clean$MAT_TUR_ANO < 2011, "ENEM"] <- FALSE
classificacao.clean[classificacao.clean$MAT_TUR_ANO >= 2011, "ENEM"] <- TRUE

classificacao.cra <- classificacao.clean %>%
  group_by(MAT_ALU_MATRICULA, EVADIU, ENEM) %>%
  mutate(cra.contrib = MAT_MEDIA_FINAL*CREDITOS) %>%
  summarise(cra = sum(cra.contrib)/sum(CREDITOS))


classificacao.model.input <- classificacao.clean %>%
  group_by(MAT_ALU_MATRICULA,disciplina)  %>%
  filter(MAT_MEDIA_FINAL == max(MAT_MEDIA_FINAL)) %>%
  ungroup() %>%
  select(MAT_ALU_MATRICULA,disciplina,MAT_MEDIA_FINAL) %>% 
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(MAT_ALU_MATRICULA ~ disciplina, mean) %>%
  merge(classificacao.cra)

##Split dos dados
split <- createDataPartition(y=classificacao.model.input$EVADIU, p = 0.90, list = FALSE)
train <- classificacao.model.input[split,]
test <- classificacao.model.input[-split,]

##to factor
train$EVADIU <- as.factor(train$EVADIU)
train$MAT_ALU_MATRICULA <- as.factor(train$MAT_ALU_MATRICULA)
train$ENEM <- as.logical(train$ENEM)

##remove NA's
train.clean <- train %>%
  filter(!is.na(Álgebra.Vetorial.e.Geometria.Analítica)) %>%
  filter(!is.na(Cálculo.Diferencial.e.Integral.I)) %>%
  filter(!is.na(Introdução.à.Computação)) %>%
  filter(!is.na(Laboratório.de.Programação.I)) %>%
  filter(!is.na(Programação.I)) %>%
  filter(!is.na(Leitura.e.Produção.de.Textos)) 

##remove NA's
test.clean <- test %>%
  filter(!is.na(Álgebra.Vetorial.e.Geometria.Analítica)) %>%
  filter(!is.na(Cálculo.Diferencial.e.Integral.I)) %>%
  filter(!is.na(Introdução.à.Computação)) %>%
  filter(!is.na(Laboratório.de.Programação.I)) %>%
  filter(!is.na(Programação.I)) %>%
  filter(!is.na(Leitura.e.Produção.de.Textos))
```


### 2.Use como atributos as médias das disciplinas mais o atributo que você criou na parte 1;

O atributo que eu escolhi avaliar foi se o aluno teve como metodo de entrada o enem. 

### 3.Treine modelos de regressão logística;

```{r glmtodasdisciplinas}
##Modelo com todas as disciplinas
model <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica 
             ,family=binomial, data=train.clean)

summary(model)

##Modelo não balanceado
table(train$EVADIU)
```
```{r glmmaisenem}
##Modelo com todas as disciplinas + ENEM
model.attr <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica + ENEM
                  ,family=binomial, data=train.clean)

##Modelo não balanceado
table(train$EVADIU)
```
> Modelos de regressão logistica balanceados

No proximo modelo foram criadas mais instancias da classe dos alunos que evadiram
```{r glmup}

library(ROSE)
library(pROC)

#oversampling
up_train <- upSample(x = train.clean[, -ncol(train.clean)],
                     y = train.clean$EVADIU)                         
table(up_train$EVADIU)

##modelo com balanceamento
model.up <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                + Introdução.à.Computação
                + Laboratório.de.Programação.I
                + Leitura.e.Produção.de.Textos
                + Programação.I
                + Álgebra.Vetorial.e.Geometria.Analítica
                ,family=binomial, data=up_train)
```

No proximo modelo foram retiradas instancias da classe dos alunos que não evadiram
```{r glmdown}

set.seed(9560)
down_train <- downSample(x = train.clean[, -ncol(train.clean)],
                         y = train.clean$EVADIU)  
table(down_train$Class)   

##modelo com balanceamento
model.down <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica
                  ,family=binomial, data=down_train)
```

No proximo modelo utilizei o package ROSE para balancear as classes
```{r glmrose}
#ROSE
set.seed(9560)
rose_train <- ROSE(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica
                  , data  = train.clean)$data                         
table(rose_train$EVADIU) 

model.rose <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica
                  ,family=binomial, data=rose_train)
```

### 4.Treine modelos de árvore de decisão;

```{r decisiontree}
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)

##modelo sem balanceamento
##Parametros de prunning default
fit <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=train.clean,
             method="class")

##overfiting
fancyRpartPlot(fit)

```


```{r decisiontreebal}

##modelo com balanceamento - oversampling
##Parametros de prunning default
fit.up <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=up_train,
             method="class")

fancyRpartPlot(fit.up)

##modelo com balanceamento - undersampling
##Parametros de prunning default
fit.down <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=down_train,
             method="class")

##overfiting
fancyRpartPlot(fit.down)

##modelo com balanceamento - ROSE package
##Parametros de prunning default
fit.bal <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=rose_train,
             method="class")

##overfiting
fancyRpartPlot(fit.bal)

```

### 5.Treine modelos de árvore de decisão;
```{r quinto}
importancia <- varImp(model, scale = FALSE)
importancia

```{
