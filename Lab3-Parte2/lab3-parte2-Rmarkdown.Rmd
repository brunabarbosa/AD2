---
title: "Lab3-parte2"
author: "Bruna Barbosa"
date: "March 1, 2017"
output: html_document
---

### 1.Separe os dados em treino e teste;
```{r setup, cache=TRUE, message=FALSE, warning=FALSE}
library(ISLR)
library(readr)
library(caret)
library(dplyr)
library(reshape2)
library(caret)

set.seed(9560)
#setwd("~/AD2/Lab3-Parte2")
treino_classificacao_v2 <- read_csv("treino_classificacao_v2.csv")

##Reshape nos dados
classificacao.clean <- treino_classificacao_v2 %>%
  filter(!is.na(MAT_MEDIA_FINAL))

classificacao.clean$CREDITOS <- 4

##novo atributo
classificacao.clean[classificacao.clean$MAT_TUR_ANO < 2011, "ENEM"] <- FALSE
classificacao.clean[classificacao.clean$MAT_TUR_ANO >= 2011, "ENEM"] <- TRUE

classificacao.cra <- classificacao.clean %>%
  group_by(MAT_ALU_MATRICULA, EVADIU, ENEM) %>%
  mutate(cra.contrib = MAT_MEDIA_FINAL*CREDITOS) %>%
  summarise(cra = sum(cra.contrib)/sum(CREDITOS))


classificacao.model.input <- classificacao.clean %>%
  group_by(MAT_ALU_MATRICULA,disciplina)  %>%
  filter(MAT_MEDIA_FINAL == max(MAT_MEDIA_FINAL)) %>%
  ungroup() %>%
  select(MAT_ALU_MATRICULA,disciplina,MAT_MEDIA_FINAL) %>% 
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(MAT_ALU_MATRICULA ~ disciplina, mean) %>%
  merge(classificacao.cra)

##Split dos dados
split <- createDataPartition(y=classificacao.model.input$EVADIU, p = 0.90, list = FALSE)
train <- classificacao.model.input[split,]
test <- classificacao.model.input[-split,]

##to factor
train$EVADIU <- as.factor(train$EVADIU)
train$MAT_ALU_MATRICULA <- as.factor(train$MAT_ALU_MATRICULA)
train$ENEM <- as.logical(train$ENEM)

##remove NA's
train.clean <- train %>%
  filter(!is.na(Álgebra.Vetorial.e.Geometria.Analítica)) %>%
  filter(!is.na(Cálculo.Diferencial.e.Integral.I)) %>%
  filter(!is.na(Introdução.à.Computação)) %>%
  filter(!is.na(Laboratório.de.Programação.I)) %>%
  filter(!is.na(Programação.I)) %>%
  filter(!is.na(Leitura.e.Produção.de.Textos)) 

##remove NA's
test.clean <- test %>%
  filter(!is.na(Álgebra.Vetorial.e.Geometria.Analítica)) %>%
  filter(!is.na(Cálculo.Diferencial.e.Integral.I)) %>%
  filter(!is.na(Introdução.à.Computação)) %>%
  filter(!is.na(Laboratório.de.Programação.I)) %>%
  filter(!is.na(Programação.I)) %>%
  filter(!is.na(Leitura.e.Produção.de.Textos))
```


### 2.Use como atributos as médias das disciplinas mais o atributo que você criou na parte 1;

O atributo que eu escolhi avaliar foi se o aluno teve como metodo de entrada o enem. 

### 3.Treine modelos de regressão logística;

```{r glmtodasdisciplinas}
##Modelo com todas as disciplinas
model <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica 
             ,family=binomial, data=train.clean)

summary(model)

##Modelo não balanceado
table(train$EVADIU)
```
```{r glmmaisenem}
##Modelo com todas as disciplinas + ENEM
model.enem <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica + ENEM
                  ,family=binomial, data=train.clean)

##Modelo não balanceado
table(train$EVADIU)
```
> Modelos de regressão logistica balanceados

No proximo modelo foram criadas mais instancias da classe dos alunos que evadiram
```{r glmup}

library(ROSE)
library(pROC)

#oversampling
up_train <- upSample(x = train.clean[, -ncol(train.clean)],
                     y = train.clean$EVADIU)                         
table(up_train$EVADIU)

##modelo com balanceamento
model.up <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                + Introdução.à.Computação
                + Laboratório.de.Programação.I
                + Leitura.e.Produção.de.Textos
                + Programação.I
                + Álgebra.Vetorial.e.Geometria.Analítica
                ,family=binomial, data=up_train)
```

No proximo modelo foram retiradas instancias da classe dos alunos que não evadiram
```{r glmdown}

set.seed(9560)
down_train <- downSample(x = train.clean[, -ncol(train.clean)],
                         y = train.clean$EVADIU)  
table(down_train$Class)   

##modelo com balanceamento
model.down <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica
                  ,family=binomial, data=down_train)
```

No proximo modelo utilizei o package ROSE para balancear as classes
```{r glmrose}
#ROSE
set.seed(9560)
rose_train <- ROSE(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica
                  , data  = train.clean)$data                         
table(rose_train$EVADIU) 

model.rose <- glm(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                  + Introdução.à.Computação
                  + Laboratório.de.Programação.I
                  + Leitura.e.Produção.de.Textos
                  + Programação.I
                  + Álgebra.Vetorial.e.Geometria.Analítica
                  ,family=binomial, data=rose_train)
```

### 4.Treine modelos de árvore de decisão;

```{r decisiontree}
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)

##modelo sem balanceamento
##Parametros de prunning default
fit <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=train.clean,
             method="class")

fancyRpartPlot(fit)

```


```{r decisiontreebal}

##modelo com balanceamento - oversampling
##Parametros de prunning default
fit.up <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=up_train,
             method="class")

fancyRpartPlot(fit.up)

##modelo com balanceamento - undersampling
##Parametros de prunning default
fit.down <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=down_train,
             method="class")

fancyRpartPlot(fit.down)

##modelo com balanceamento - ROSE package
##Parametros de prunning default
fit.rose <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
             + Introdução.à.Computação
             + Laboratório.de.Programação.I
             + Leitura.e.Produção.de.Textos
             + Programação.I
             + Álgebra.Vetorial.e.Geometria.Analítica,
             data=rose_train,
             method="class")

fancyRpartPlot(fit.rose)



```

### 5.Treine modelos de árvore de decisão;

```{r importance}

importancia <- varImp(model, scale = FALSE)
importancia
```

O atributo mais importante para a regressão logistica com todas as disciplinas são
1. Introdução.à.Computação [2.9459793]
2. Leitura.e.Produção.de.Textos [1.7052697]

### 6.Reporte acurácia, precision e recall no treino e teste. 
Como você avalia os resultados? Justifique sua resposta.


```{r acuraciatreino}
#Acuracia treino para a regressao logistica
# MEASURING THE PREDICTIVE ABILITY OF THE MODEL
fitted.results <- predict(model,newdata=train.clean,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != train.clean$EVADIU)
print(paste('Accuracy',1-misClasificError))
accuracy.meas(train.clean$EVADIU, fitted.results)
```


```{r acuraciateste}
#Acuracia teste para a regressao logistica
# MEASURING THE PREDICTIVE ABILITY OF THE MODEL
fitted.results <- predict(model,newdata=test.clean,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != test.clean$EVADIU)
print(paste('Accuracy',1-misClasificError))
accuracy.meas(test.clean$EVADIU, fitted.results)
```
Por algum problema no codigo, a acuracia da predição dos dados de treino é zero
e nos dados de teste a acuracia é aproximadamente 0.9.
Isso pode se dar pois a classe no teste esta desbalanceada e o teste possui poucas instancias onde 
o aluno nao evadiu.

### 7.  Controle overfitting usando validação-cruzada (ridge e lasso na regressão logística e condições de "early stopping" nas árvores de decisão, por exemplo, profundidade da árvore);

```{r regressaologistica}
#Acuracia teste para a regressao logistica com validacao-cruzada
library(caret)


fitControl <- trainControl(method = "cv",
                           number = 10)
# Set seq of lambda to test
lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

glmfit <- train(EVADIU ~ Cálculo.Diferencial.e.Integral.I
                + Introdução.à.Computação
                + Laboratório.de.Programação.I
                + Leitura.e.Produção.de.Textos
                + Programação.I
                + Álgebra.Vetorial.e.Geometria.Analítica,
                data = train.clean,
                method='glm',
                trControl = fitControl,
                preProc=c('scale', 'center'))
glmfit

coef(glmfit$finalModel)
glmfit.pred <- predict(glmfit, test.clean)

```

```{r decisiontreeprune}
#Decision tree com atributos de pruning alterados (cp e minsplit)
fitprune <- rpart(EVADIU ~ Cálculo.Diferencial.e.Integral.I
              + Introdução.à.Computação
              + Laboratório.de.Programação.I
              + Leitura.e.Produção.de.Textos
              + Programação.I
              + Álgebra.Vetorial.e.Geometria.Analítica,
              data=train.clean,
              method="class",
              control=rpart.control(minsplit=20, cp=0.02))

Prediction.fit2 <- predict(fitprune, test.clean, type = "class")
accuracy.meas(test.clean$EVADIU,Prediction.fit2)

```

### 8. Reporte acurácia, precision e recall da validação-cruzada e teste (para os melhores modelos);
A metrica que escolhi para obter o melhor modelo é a curva ROC (Receiver Operating Characteristics) para medir a 
acuracia das predicoes nos dados de teste. A curva ROC é formada pelo plot da TP rate (Sensitivity) e FP rate (Specificity).

```{r bestmodel}
fitted.results <- predict(model,newdata=test.clean,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

fitted.results.attr <- predict(model.enem,newdata=test.clean,type='response')
fitted.results.attr <- ifelse(fitted.results.attr > 0.5,1,0)

#oversampling
fitted.results.up <- predict(model.up,newdata=test.clean,type='response')
fitted.results.up <- ifelse(fitted.results.up > 0.5,1,0)

#undersampling
fitted.results.under <- predict(model.down,newdata=test.clean,type='response')
fitted.results.under <- ifelse(fitted.results.under > 0.5,1,0)

#ROSE
fitted.results.rose <- predict(model.rose,newdata=test.clean,type='response')
fitted.results.rose <- ifelse(fitted.results.rose > 0.5,1,0)

##decision tree nao balanceada
fitted.results.dt <- predict(fit, newdata=test.clean, type = "class")

##decision tree balanceada
#oversampling
fitted.results.dt.up <- predict(fit.up,newdata=test.clean, type = "class")

#undersampling
fitted.results.dt.under <- predict(fit.down,newdata=test.clean, type = "class")

#ROSE
fitted.results.dt.rose <- predict(fit.rose,newdata=test.clean, type = "class")

#AUC ROSE
##regressao logistica
roc.curve(test.clean$EVADIU, fitted.results, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.attr, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.up, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.under, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.rose, plotit = F)

#arvore de decisao
roc.curve(test.clean$EVADIU, fitted.results.dt, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.dt.up, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.dt.under, plotit = F)
roc.curve(test.clean$EVADIU, fitted.results.dt.rose, plotit = F)

roc.curve(test.clean$EVADIU,glmfit.pred, plotit = F)
roc.curve(test.clean$EVADIU,Prediction.fit2, plotit = F)
```
### 9. Aplique o melhor modelo a você mesmo(a) usando seu histórico e reporte a predição e resultado.

O melhor modelo de acordo com a metrica escolhida (curva ROC) é a regressao logistica balanceada
com o metodo de undersampling.

```{r meuhist}

newdata = data.frame(Cálculo.Diferencial.e.Integral.I = 5.7,
                       Introdução.à.Computação = 8.2,
                       Laboratório.de.Programação.I = 8.7,
                       Leitura.e.Produção.de.Textos = 7.8,
                       Programação.I = 8.7,
                       Álgebra.Vetorial.e.Geometria.Analítica = 5.9)

#Com todas as variaveis                     
result <- predict(model.down, newdata)
result <- ifelse(result > 0.5,'TRUE','FALSE')
result
```

A predição do melhor modelo mostrou que de acordo com as notas do meu primeiro periodo eu nao irei evadir o curso.

